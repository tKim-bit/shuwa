import streamlit as st
from diffusers import StableDiffusionPipeline
import torch
import random
import os
from PIL import Image
import cv2
import mediapipe as mp
import numpy as np
import math

from streamlit_webrtc import webrtc_streamer, VideoTransformerBase

def calc_angle(a, b, c):
    ba = [a[0] - b[0], a[1] - b[1]]
    bc = [c[0] - b[0], c[1] - b[1]]
    dot = ba[0]*bc[0] + ba[1]*bc[1]
    norm_ba = math.sqrt(ba[0]**2 + ba[1]**2)
    norm_bc = math.sqrt(bc[0]**2 + bc[1]**2)
    cos_angle = dot / (norm_ba * norm_bc + 1e-6)
    angle = math.degrees(math.acos(min(1.0, max(-1.0, cos_angle))))
    return angle

def mediapipe_reset():
    mp_hands = mp.solutions.hands
    mp_drawing = mp.solutions.drawing_utils
    hands = mp_hands.Hands(static_image_mode=True, max_num_hands=2, min_detection_confidence=0.5, min_tracking_confidence=0.5)
    return mp_hands, mp_drawing, hands

def camera_input():
    return st.camera_input("ğŸ“¸ æŒ‡ã®æœ¬æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆã™ã‚‹å†™çœŸã‚’æ’®ã£ã¦ãã ã•ã„")

def mediapipe_prosess(uploaded_file, mp_hands, mp_drawing, hands):
    if uploaded_file is not None:
        file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
        img = cv2.imdecode(file_bytes, 1)
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        results = hands.process(img_rgb)

        total_finger_count = 0
        annotated_img = img.copy()

        if results.multi_hand_landmarks:
            for hand_idx, hand_landmarks in enumerate(results.multi_hand_landmarks):
                mp_drawing.draw_landmarks(
                    annotated_img,
                    hand_landmarks,
                    mp_hands.HAND_CONNECTIONS,
                    mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2),
                    mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2)
                )

                landmarks = []
                for id, lm in enumerate(hand_landmarks.landmark):
                    h, w, c = img.shape
                    cx, cy = int(lm.x * w), int(lm.y * h)
                    landmarks.append([id, cx, cy])

                if landmarks:
                    fingers = 0
                    mcp = landmarks[mp_hands.HandLandmark.THUMB_MCP][1:3]
                    ip  = landmarks[mp_hands.HandLandmark.THUMB_IP][1:3]
                    tip = landmarks[mp_hands.HandLandmark.THUMB_TIP][1:3]
                    thumb_angle = calc_angle(mcp, ip, tip)
                    if thumb_angle > 160:
                        fingers += 1

                    if landmarks[mp_hands.HandLandmark.INDEX_FINGER_TIP][2] < landmarks[mp_hands.HandLandmark.INDEX_FINGER_PIP][2]:
                        fingers += 1
                    if landmarks[mp_hands.HandLandmark.MIDDLE_FINGER_TIP][2] < landmarks[mp_hands.HandLandmark.MIDDLE_FINGER_PIP][2]:
                        fingers += 1
                    if landmarks[mp_hands.HandLandmark.RING_FINGER_TIP][2] < landmarks[mp_hands.HandLandmark.RING_FINGER_PIP][2]:
                        fingers += 1
                    if landmarks[mp_hands.HandLandmark.PINKY_TIP][2] < landmarks[mp_hands.HandLandmark.PINKY_PIP][2]:
                        fingers += 1

                    total_finger_count += fingers
        return total_finger_count
    else:
        return 0

def camera():
    mp_hands, mp_drawing, hands = mediapipe_reset()
    uploaded_file = camera_input()
    if uploaded_file is not None:
        total_finger_count = mediapipe_prosess(uploaded_file, mp_hands, mp_drawing, hands)
        if total_finger_count > 0:
            st.success(f"ç”»åƒå†…ã§**{total_finger_count}æœ¬**ã®æŒ‡ãŒä¼¸ã³ã¦ã„ã‚‹ã¨æ¤œå‡ºã—ã¾ã—ãŸï¼")
            if st.button("âœ… ã“ã®çµæœã§æ¬¡ã¸é€²ã‚€"):
                return total_finger_count
        else:
            st.warning("ä¼¸ã³ã¦ã„ã‚‹æŒ‡ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚ã‚‚ã†ä¸€åº¦è©¦ã—ã¦ãã ã•ã„ã€‚")
    return None

device = "cuda" if torch.cuda.is_available() else "cpu"

@st.cache_resource(show_spinner=False)
def load_diffusion_model():
    pipe = StableDiffusionPipeline.from_pretrained(
        "Lykon/dreamshaper-6",
        torch_dtype=torch.float16 if device == "cuda" else torch.float32,
        safety_checker=None,
        use_safetensors=True
    )
    return pipe.to(device)

@st.cache_resource(show_spinner=False)
def load_yolov5_model():
    model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)
    return model

def detect_objects_yolov5(model, image_path):
    results = model(image_path)
    df = results.pandas().xyxy[0]
    return len(df)
# --- ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ï¼ˆä»®å®šç¾©ï¼‰ ---
def reset_game_state():
    keys_to_reset = [
        "v001_fruit", "v001_num", "v001_image_path", "v001_detected_count",
        "v001_generated", "v001_result_shown", "v001_camera1_count", "v001_camera2_count",
        "v001_guess", "v001_photo1_taken", "v001_photo2_taken", "v001_answer_checked",
        "last_result_message", "last_result_type", "last_actual_num_message"
    ]
    for key in keys_to_reset:
        if key in st.session_state:
            del st.session_state[key]

def camera_input_widget(label, key):
    return st.camera_input(label, key=key)

def mediapipe_process(uploaded_file, mp_hands, mp_drawing, hands):
    return mediapipe_prosess(uploaded_file, mp_hands, mp_drawing, hands)


screen = st.sidebar.selectbox("", ["æ•°å½“ã¦", "æ‰‹è©±","æ•°å½“ã¦ver0.0.1"])
if screen == "æ•°å½“ã¦":
    # åˆæœŸåŒ–
    fruit_options = ["ã‚Šã‚“ã”", "ã¿ã‹ã‚“"]
    if "fruit" not in st.session_state:
        st.session_state.fruit = random.choice(fruit_options)
        st.session_state.image_path = None
        st.session_state.generated = False
        st.session_state.result_shown = False

    # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
    pipe = load_diffusion_model()
    yolo_model = load_yolov5_model()

    st.title("ğŸ æœç‰©å½“ã¦ã‚²ãƒ¼ãƒ ï¼ˆç‰©ä½“æ¤œçŸ¥ã§æ­£è§£ã‚’è‡ªå‹•åˆ¤å®šï¼‰ğŸŠ")
    st.write("ç”»åƒã«æ˜ ã‚‹æœç‰©ã®æ•°ã‚’äºˆæƒ³ã—ã¦ã­ï¼ï¼ˆç­”ãˆã¯1ã€œ10ã®ç¯„å›²ã§ã™ï¼‰")

    # ç”»åƒç”Ÿæˆ
    if not st.session_state.generated:
        fruit = st.session_state.fruit
        eng = "red apples" if fruit == "ã‚Šã‚“ã”" else "oranges"

        while True:
            num = random.randint(1, 10)
            st.session_state.num = num

            prompt = (
                f"A high-resolution, realistic photo showing exactly {num} whole, clearly visible, and similarly sized {eng}, "
                "all fully in frame and evenly distributed on a clean white tabletop. No overlapping. "
                "Each fruit should be around palm-sized and spaced apart. Shot with soft, natural lighting, ultra-detailed, 4k quality."
            )

            with st.spinner(f"ç”Ÿæˆä¸­..."):
                image = pipe(prompt, height=512, width=512, num_inference_steps=30).images[0]

            save_path = "generated_fruit.png"
            image.save(save_path)
            st.session_state.image_path = save_path

            detected = detect_objects_yolov5(yolo_model, save_path)

            if detected <= 10:
                st.session_state.detected_count = detected
                break
            else:
                st.warning(f"âš ï¸ {detected}å€‹æ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚ã‚„ã‚Šç›´ã—ã¾ã™...")

        st.session_state.generated = True

    # ç”»åƒè¡¨ç¤º
    if st.session_state.image_path and os.path.exists(st.session_state.image_path):
        st.image(st.session_state.image_path, caption="ã“ã®ä¸­ã«ä½•å€‹ã‚ã‚‹ï¼Ÿ", use_container_width=True)
    else:
        st.warning("ç”»åƒãŒã¾ã ç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

    # ã‚«ãƒ¡ãƒ©ã§æŒ‡ã®æ•°ã‚’å…¥åŠ›ï¼ˆäºˆæƒ³ï¼‰
    st.info("ãƒ’ãƒ³ãƒˆï¼šæœç‰©ã®æ•°ã¯ 1ã€œ10 ã®é–“ã§ã™ã€‚")
    st.write("ã„ãã¤ã‚ã‚‹ã¨æ€ã„ã¾ã™ã‹ï¼Ÿï¼ˆæŒ‡ã§å…¥åŠ›ï¼‰")
    guess = camera()
    if guess is not None:
        st.session_state.guess = guess
        st.write(f'è§£ç­”: {guess} å€‹')

    # ç­”ãˆåˆã‚ã›
    if st.button("ç­”ãˆåˆã‚ã›"):
        if "guess" not in st.session_state:
            st.warning("ã¾ãšæŒ‡ã‚’ä½¿ã£ã¦æœç‰©ã®æ•°ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        else:
            answer = st.session_state.detected_count
            guess = st.session_state.guess
            fruit = st.session_state.fruit
            if guess == answer:
                st.success(f"ğŸ‰ æ­£è§£ï¼{fruit}ã¯ {answer} å€‹ã‚ã‚Šã¾ã—ãŸï¼")
            else:
                st.error(f"ğŸ˜¢ æ®‹å¿µï¼æ­£è§£ã¯ {answer} å€‹ã® {fruit} ã§ã—ãŸã€‚")
            st.info(f'å®Ÿéš›ã¯{fruit}ã‚’{st.session_state.num}å€‹ã§ç”Ÿæˆã—ãŸç”»åƒã§ã™')
            st.session_state.result_shown = True

    # ã‚‚ã†ä¸€åº¦ãƒœã‚¿ãƒ³
    if st.session_state.result_shown:
        if st.button("ã‚‚ã†ä¸€åº¦éŠã¶"):
            st.session_state.clear()
elif screen == "æ‰‹è©±":
    # MediapipeåˆæœŸåŒ–
    mp_hands = mp.solutions.hands
    mp_drawing = mp.solutions.drawing_utils
    hands = mp_hands.Hands(static_image_mode=True, max_num_hands=1)

    st.title("âœ‹ æŒ‡ã®æœ¬æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆã—ã¦æŒ¨æ‹¶ã‚¯ã‚¤ã‚º")

    # æŒ‡ã®æœ¬æ•°ã‚’æ•°ãˆã‚‹é–¢æ•°
    def count_fingers(hand_landmarks):
        finger_count = 0
        landmarks = hand_landmarks.landmark

        tips = [8, 12, 16, 20]
        pips = [6, 10, 14, 18]
        for tip, pip in zip(tips, pips):
            if landmarks[tip].y < landmarks[pip].y:
                finger_count += 1

        # è¦ªæŒ‡ï¼ˆå³æ‰‹åŸºæº–ï¼‰
        if landmarks[4].x < landmarks[3].x:
            finger_count += 1

        return finger_count

    # æŒ‡ã®æœ¬æ•°ã§æŒ¨æ‹¶ã‚’åˆ†é¡
    def classify_greeting(count):
        if count == 1:
            return "ã“ã‚“ã«ã¡ã¯"
        elif count == 5:
            return "ã‚ã‚ŠãŒã¨ã†"
        elif count == 0:
            return "ãƒã‚¤ãƒã‚¤"
        else:
            return "èªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸ"

    # ãƒ“ãƒ‡ã‚ªå‡¦ç†ã‚¯ãƒ©ã‚¹
    class HandShot(VideoTransformerBase):
        def __init__(self):
            self.frame = None
        def transform(self, frame):
            self.frame = frame.to_ndarray(format="bgr24")
            return self.frame

    ctx = webrtc_streamer(
        key="finger-count",
        video_processor_factory=HandShot,
        media_stream_constraints={"video": True, "audio": False},
        async_processing=True,
    )

    captured_image_placeholder = st.empty()
    result_placeholder = st.empty()

    # æ’®å½±ãƒœã‚¿ãƒ³
    if st.button("ğŸ“¸ æ’®å½±ã—ã¦æŒ‡ã®æœ¬æ•°ã‚’èªè­˜ã—ã‚¯ã‚¤ã‚ºé–‹å§‹"):
        if ctx.video_processor and ctx.video_processor.frame is not None:
            image = ctx.video_processor.frame.copy()
            rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            results = hands.process(rgb)

            if results.multi_hand_landmarks:
                hand_landmarks = results.multi_hand_landmarks[0]
                mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)

                count = count_fingers(hand_landmarks)
                greeting = classify_greeting(count)

                # æ’®å½±çµæœç”»åƒã‚’è¡¨ç¤º
                captured_image_placeholder.image(image, caption="æ’®å½±çµæœ", channels="BGR")

                # ã‚¯ã‚¤ã‚ºå•é¡Œã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
                st.session_state.quiz_greeting = greeting
                st.session_state.quiz_answered = False

                result_placeholder.info("ã‚¯ã‚¤ã‚ºé–‹å§‹ï¼ã“ã®æ‰‹è©±ã¯ä½•ã®æŒ¨æ‹¶ã§ã—ã‚‡ã†ã‹ï¼Ÿ ä¸‹ã®å…¥åŠ›æ¬„ã«ç­”ãˆã¦ãã ã•ã„ã€‚")

            else:
                result_placeholder.warning("æ‰‹ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚ã‚‚ã†ä¸€åº¦æ’®å½±ã—ã¦ãã ã•ã„ã€‚")
        else:
            st.error("ç”»åƒãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

    # ã‚¯ã‚¤ã‚ºå›ç­”å…¥åŠ›æ¬„
    if "quiz_greeting" in st.session_state and not st.session_state.get("quiz_answered", False):
        user_input = st.text_input("æŒ¨æ‹¶ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šã“ã‚“ã«ã¡ã¯ã€ã‚ã‚ŠãŒã¨ã†ã€ãƒã‚¤ãƒã‚¤ï¼‰")

        if st.button("å›ç­”ã™ã‚‹"):
            correct_answer = st.session_state.quiz_greeting
            if user_input == correct_answer:
                result_placeholder.success(f"æ­£è§£ï¼ã“ã®æ‰‹è©±ã¯ã€Œ{correct_answer}ã€ã§ã™ã€‚")
            else:
                result_placeholder.error(f"ä¸æ­£è§£ï¼æ­£è§£ã¯ã€Œ{correct_answer}ã€ã§ã™ã€‚")

            st.session_state.quiz_answered = True

    # ç­”ãˆçµ‚ã‚ã£ãŸã‚‰ã‚‚ã†ä¸€åº¦æ’®å½±ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãƒªãƒˆãƒ©ã‚¤å¯èƒ½
# --- ver0.0.1 ãƒ¢ãƒ¼ãƒ‰æœ¬ä½“ ---
elif screen == "æ•°å½“ã¦ver0.0.1":
    fruit_options = ["ã‚Šã‚“ã”", "ã¿ã‹ã‚“"]
    if "v001_consecutive_streak" not in st.session_state:
        st.session_state.v001_consecutive_streak = 0

    if "v001_fruit" not in st.session_state:
        reset_game_state()

    pipe = load_diffusion_model()
    yolo_model = load_yolov5_model()

    st.title("æœç‰©å½“ã¦ã‚²ãƒ¼ãƒ  ver0.0.1")
    st.write("ç”»åƒã«æ˜ ã‚‹æœç‰©ã®æ•°ã‚’äºˆæƒ³ã—ã¦ã­ï¼ï¼ˆç­”ãˆã¯1ã€œ10ã®ç¯„å›²ã§ã™ï¼‰")
    st.write(f"é€£ç¶šæ­£è§£è¨˜éŒ²: **{st.session_state.v001_consecutive_streak}** å›")

    if not st.session_state.get("v001_generated", False):
        st.session_state.v001_fruit = random.choice(fruit_options)
        fruit = st.session_state.v001_fruit
        eng = "red apples" if fruit == "ã‚Šã‚“ã”" else "oranges"

        while True:
            num = random.randint(1, 10)
            st.session_state.v001_num = num

            prompt = (
                f"A high-resolution, realistic photo showing exactly {num} whole, clearly visible, and similarly sized {eng}, "
                "all fully in frame and evenly distributed on a clean white tabletop. No overlapping. "
                "Each fruit should be around palm-sized and spaced apart. Shot with soft, natural lighting, ultra-detailed, 4k quality."
            )

            with st.spinner("ç”Ÿæˆä¸­..."):
                image = pipe(prompt, height=512, width=512, num_inference_steps=30).images[0]

            save_path = "generated_fruit.png"
            image.save(save_path)
            st.session_state.v001_image_path = save_path

            detected = detect_objects_yolov5(yolo_model, save_path)

            if detected <= 10:
                st.session_state.v001_detected_count = detected
                break
            else:
                st.warning(f"{detected}å€‹æ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚ã‚„ã‚Šç›´ã—ã¾ã™...")

        st.session_state.v001_generated = True

    if st.session_state.get("v001_image_path") and os.path.exists(st.session_state.v001_image_path):
        st.image(st.session_state.v001_image_path, caption="ã“ã®ä¸­ã«ä½•å€‹ã‚ã‚‹ï¼Ÿ", use_container_width=True)

    st.info("ãƒ’ãƒ³ãƒˆï¼šæœç‰©ã®æ•°ã¯ 1ã€œ10 ã®é–“ã§ã™ã€‚")
    st.write("ã„ãã¤ã‚ã‚‹ã¨æ€ã„ã¾ã™ã‹ï¼Ÿï¼ˆæŒ‡ã§å…¥åŠ› - 2æšã®å†™çœŸã‚’æ’®ã£ã¦åˆè¨ˆã—ã¾ã™ï¼‰")

    mp_hands, mp_drawing, hands = mediapipe_reset()

    if not st.session_state.get("v001_photo1_taken", False):
        st.subheader("ğŸ“¸ 1æšç›®ã®å†™çœŸã‚’æ’®ã£ã¦ãã ã•ã„")
        uploaded_file1 = camera_input_widget("1æšç›®ã®å†™çœŸ", key="v001_camera1_input")
        if uploaded_file1 is not None:
            count1 = mediapipe_process(uploaded_file1, mp_hands, mp_drawing, hands)
            st.session_state.v001_camera1_count = count1
            st.success(f"1æšç›®ã§{count1}æœ¬ã®æŒ‡ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
            if st.button("âœ… æ¬¡ã¸", key="v001_confirm_photo1"):
                st.session_state.v001_photo1_taken = True
                st.rerun()
    else:
        st.info(f"1æšç›®ã®æŒ‡ã®æ•°: {st.session_state.v001_camera1_count}æœ¬ (ç¢ºå®šæ¸ˆã¿)")

    if st.session_state.get("v001_photo1_taken") and not st.session_state.get("v001_photo2_taken"):
        st.subheader("ğŸ“¸ 2æšç›®ã®å†™çœŸã‚’æ’®ã£ã¦ãã ã•ã„")
        uploaded_file2 = camera_input_widget("2æšç›®ã®å†™çœŸ", key="v001_camera2_input")
        if uploaded_file2 is not None:
            count2 = mediapipe_process(uploaded_file2, mp_hands, mp_drawing, hands)
            st.session_state.v001_camera2_count = count2
            st.success(f"2æšç›®ã§{count2}æœ¬ã®æŒ‡ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
            if st.button("âœ… çµæœã‚’è¦‹ã‚‹", key="v001_confirm_photo2"):
                st.session_state.v001_photo2_taken = True
                st.session_state.v001_guess = st.session_state.v001_camera1_count + st.session_state.v001_camera2_count
                st.success(f"åˆè¨ˆã®äºˆæƒ³: {st.session_state.v001_guess} å€‹")
                st.rerun()
    elif st.session_state.get("v001_photo1_taken") and st.session_state.get("v001_photo2_taken"):
        st.info(f"2æšç›®ã®æŒ‡ã®æ•°: {st.session_state.v001_camera2_count}æœ¬ (ç¢ºå®šæ¸ˆã¿)")
        st.success(f"åˆè¨ˆã®äºˆæƒ³: {st.session_state.v001_guess} å€‹")

    if st.session_state.get("v001_photo1_taken") and st.session_state.get("v001_photo2_taken") and st.session_state.get("v001_guess") is not None:
        if not st.session_state.get("v001_answer_checked", False):
            if st.button("ç­”ãˆåˆã‚ã›", key="v001_check_answer"):
                answer = st.session_state.v001_detected_count
                guess = st.session_state.v001_guess
                fruit = st.session_state.v001_fruit

                if guess == answer:
                    st.session_state.last_result_message = f"ğŸ‰ æ­£è§£ï¼{fruit}ã¯ {answer} å€‹ã§ã—ãŸï¼"
                    st.session_state.last_result_type = "success"
                    st.session_state.v001_consecutive_streak += 1
                else:
                    st.session_state.last_result_message = f"ğŸ˜¢ æ®‹å¿µï¼æ­£è§£ã¯ {answer} å€‹ã® {fruit} ã§ã—ãŸã€‚"
                    st.session_state.last_result_type = "error"
                    st.session_state.v001_consecutive_streak = 0

                st.session_state.last_actual_num_message = f'å®Ÿéš›ã¯{fruit}ã‚’{st.session_state.v001_num}å€‹ã§ç”Ÿæˆã—ã¾ã—ãŸ'
                st.session_state.v001_result_shown = True
                st.session_state.v001_answer_checked = True
        else:
            st.info("ç­”ãˆåˆã‚ã›ã¯å®Œäº†ã—ã¦ã„ã¾ã™ã€‚")

    if st.session_state.get("v001_result_shown"):
        if st.session_state.last_result_type == "success":
            st.success(st.session_state.last_result_message)
        else:
            st.error(st.session_state.last_result_message)
        st.info(st.session_state.last_actual_num_message)
        st.write(f"ç¾åœ¨ã®é€£ç¶šæ­£è§£è¨˜éŒ²: {st.session_state.v001_consecutive_streak} å›")

        if st.button("ã‚‚ã†ä¸€åº¦éŠã¶", key="v001_play_again"):
            reset_game_state()
            st.rerun()